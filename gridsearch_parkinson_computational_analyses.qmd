---
title: "Balancing Exploration and Exploitation in Parkinson’s Disease: Computational Analyses"
author: 
  - Björn Meder
  - Martha Sterf
  - Charley M. Wu
  - Matthias Guggenmos
date: "`r format(Sys.time(), '%d %B, %Y')`"
format:
  html:
    toc: true
    theme: zephyr
    code-fold: true
    toc-location: left-body
    classoption: fleqn
    lightbox: true
     
  pdf:
    toc: true
  docx:
    toc: true
editor: 
  default: source
editor_options: 
  chunk_output_type: console
bibliography: gridsearch_parkinson.bib
csl: https://www.zotero.org/styles/apa
cite-method: citeproc
---


```{r, results = "hide", message=FALSE}
# Housekeeping: Load packages and helper functions
# Housekeeping
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(fig.align='center')

options(knitr.kable.NA = '')

packages <- c('gridExtra', 'BayesFactor', 'tidyverse', "RColorBrewer", "lme4", "sjPlot", "lsr", "brms", "kableExtra", "afex", "emmeans", "viridis", "ggpubr", "hms", "scales")
lapply(packages, require, character.only = TRUE)

set.seed(0815)

# file with various statistical functions, among other things it provides tests for Bayes Factors (BFs)
source('statisticalTests.R')

# Wrapper for brm models such that it saves the full model the first time it is run, otherwise it loads it from disk
run_model <- function(expr, modelName, path='brm', reuse = TRUE) {
  path <- paste0(path,'/', modelName, ".brm")
  if (reuse) {
    fit <- suppressWarnings(try(readRDS(path), silent = TRUE))
  }
  if (is(fit, "try-error")) {
    fit <- eval(expr)
    saveRDS(fit, file = path)
  }
  fit
}


# Setting some plotting params
w_box          <- 0.2      # width of boxplot, also used for jittering points and lines    
line_jitter    <- w_box / 2
xAnnotate      <- -0.3

# jitter params
jit_height  <- 0.01
jit_width   <- 0.05
jit_alpha   <- 0.6

# colors for age groups
groupcolors <- c("#1b9e77", "#d95f02", "#7570b3")

```

```{r}
# read data
dat       <- read_delim("data/data_gridsearch_parkinson.csv", 
                        delim = ",",
                        col_types = cols(
                          id = readr::col_factor(),
                          group = readr::col_factor(),
                          gender = readr::col_factor(),
                          z = col_double(),        
                          zscaled = col_double(),
                          hoehn_yahr = col_double()
                        ))

# clean up
dat <- dat %>%
  select(-condition, -comments) %>% 
  mutate(group = case_match(group,
                            "PPD-" ~ "PD-",
                            "PPD+" ~ "PD+",
                            "PNP" ~ "PNP",
                            .default = NA)) %>% 
  mutate(group = factor(group, levels = c("PNP", "PD+", "PD-")))  %>% 
  mutate(type_choice = factor(type_choice, levels = c("Repeat", "Near", "Far")))  %>% 
  mutate(gender = recode(gender, "w" = "f")) %>% 
  rename(MMSE = `mini_mental`) %>% 
  mutate(last_ldopa = if_else(group != "PNP", as_hms(last_ldopa), as_hms(NA)),
         next_ldopa = if_else(group != "PNP", as_hms(next_ldopa), as_hms(NA)),
         time_exp = if_else(group != "PNP", as_hms(time_exp), as_hms(NA))) %>% 
  mutate(time_since_ldopa = as.numeric(time_exp - last_ldopa, unit = "mins"))

# get subject information
df_sample <- dat %>% 
  select(id, age, gender,group,BDI,MMSE,hoehn_yahr,last_ldopa,next_ldopa,time_exp,time_since_ldopa) %>% 
  group_by(id) %>%
  slice_head(n = 1) %>% 
  arrange(group)

# head(dat) %>%
#   kable("html", caption = "Behavioral data.") %>%
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F) %>% 
#   scroll_box(width = "100%", height = "300px")

```
# Computational Analyses

In addition to the behavioral analyses, we study exploration and exploitation in PD through the lens of the Gaussian Process Upper Confidence Bound (GP-UCB) model, a computational model that integrates similarity-based generalization with two distinct exploration mechanisms: _directed exploration_, which seeks to reduce uncertainty about rewards, and _random exploration_, which adds stochastic noise to the search process without being directed towards a particular goal. In previous research using the same paradigm, this model has provided the best account of human behavior and enabled the decomposition of exploration into distinct mechanisms
[@Wu:2018grid; @Schulz:2019kwg; @Wu:2020neurogrid; @Meder_directed__random_exploration_children; @Giron_et_al-2022-development_optimization; @Wu_et_al-generalization].


## Gaussian Process Upper Confidence Bound (GP-UCB) Model

The GP-UCB model comprises three components:

1. a _learning model_, which uses Bayesian inference to generate predictions about the rewards associated with each option (tile),
2. a _sampling strategy_, which uses reward expectations and associated uncertainty to evaluate how promising each option is, and
3. a _choice rule_, which converts options' values into choice probabilities.

::: callout-note
Add details
:::
### Learning Model
### Sampling Strategy
### Choice rule

Associated with each model component is a free parameter that we estimate through out-of-sample cross validation. These parameters provide a window into distinct aspects of learning and exploration: 

1. The length-scale parameter $\lambda$ of the RBF kernel captures how strongly a participant generalizes based on the observed evidence, i.e., the rewards obtained from previous choices.
2. The uncertainty bonus $\beta$ represents to the level of directed exploration, i.e., how much expected rewards are inflated through an "uncertainty bonus".
3. The temperature parameter $\tau$ corresponds to the amount of sampling noise, i.e., extent of random exploration. 

## Model comparison

We tested the GP-UCB model in its ability to model learning and predicting each participants' search and decision-making behavior. To assess the contribution of each component of the model (generalization, uncertainty-directed exploration, and random exploration) we compare the predictive accuracy of the GP-UCB model to model variants where we lesion away each component.

$\lambda$


All models were fitted using leave-one-round-out cross-validation based on maximum likelihood estimation. Model fits are evaluated using the sum of negative log-likelihoods across all out-of-sample predictions.

Out-of-sample predictive accuracy was assessed using a pseudo-$R^2$ measure, based on the sum of negative log-likelihoods across all out-of-sample predictions. The summed negative log likelihoods are compared to a random model, such that $R^2=0$ corresponds to chance performance and $R^2=1$ corresponds to theoretically perfect predictions. 

$$
    R^2 = 1 - \frac{\log \mathcal{L}(M_k)}{\log\mathcal{L}(M_{rand})},
$$



```{r}
modelFits <- read.csv('data/modelFit.csv')
groupDF <- dat %>% filter(round==1 & trial==0) #Get one row per participant
# modelFits <- merge(modelFits, groupDF[,c('id', 'group', 'condition')], by = "id") #merge to add group and condition data
modelFits <- merge(modelFits, groupDF[,c('id', 'group')], by = "id") #merge to add group and condition data

modelFits <-  modelFits %>%
  mutate(kernel=factor(kernel, levels=c('RBF', 'BMT'), labels=c('GP', 'BMT'))) #%>%
  # mutate(group = case_match(group,
  #                           "PPD-" ~ "PD-",
  #                           "PPD+" ~ "PD+",
  #                           "PNP" ~ "PNP",
  #                           .default = NA)) %>%
  # mutate(group = factor(group, levels = c("PNP", "PD+", "PD-")))

modelFits$ModelName = paste(modelFits$kernel, modelFits$acq, sep="-")
modelFits$ModelName = factor(modelFits$ModelName, levels = c('GP-UCB', 'BMT-UCB', 'GP-GM', 'BMT-GM', 'GP-GV', 'BMT-GV'))
modelFits$acq <- factor(modelFits$acq, levels = c('UCB', 'GM', 'GV'))

#Only include key comparisons
modelFits <- subset(modelFits, ModelName %in% c('GP-UCB', 'GP-GM', 'BMT-UCB'))

#Two line name for models
modelFits$shortname <- factor(modelFits$ModelName, levels = c('GP-UCB','BMT-UCB', 'GP-GM'))
levels(modelFits$shortname) <- c('GP\nUCB', 'lambda\nlesion', 'beta\nlesion')

ggboxplot(modelFits, 
          x = "shortname", 
          y = "R2",
          color = "group", palette =groupcolors, fill = "group", alpha = 0.2,
          add = "jitter", jitter.size = 0.5, shape = "group", title = "Model comparison") +
  facet_wrap(~group, nrow = 1) +
  ylab(bquote(R^2)) +
  xlab("") +
  stat_compare_means(
  comparisons = list( 
    c("GP\nUCB", "lambda\nlesion"), 
    c("GP\nUCB", "beta\nlesion"), 
    c("lambda\nlesion", "beta\nlesion")  
  ), 
  paired = TRUE, 
  method = "t.test", 
   aes(label = paste0("p = ", after_stat(p.format)))
  
) +
  stat_summary(fun = mean, geom="point", shape = 23, fill = "white", size=2) +
  theme_classic() +
  theme(strip.background = element_blank(),  
        strip.text = element_text(color = "black", size=12),
        legend.position = "none"
  )

ggsave("plots/model_comparison.png", width = 9, height = 5)
# p_R2_comp <- 
  # ggplot(modelFits, aes(x=shortname, y=R2, fill=NA,color=shortname)) +
  # #geom_line(aes(group=id), color = 'grey', alpha  = 0.3)+
  # geom_quasirandom( size = 0.5)+
  # geom_boxplot(width = 0.4, color ='black', outlier.shape=NA, fill = NA)+
  # stat_summary(fun.y = mean, geom='point', shape = 23, color = 'black', fill = 'white')+
  # xlab('') +
  # ylab(expression(R^2)) +
  # #ylab(expression(italic(pxp))) +
  # scale_color_manual(values=modelPal, name = 'Model', labels = expression('GP-UCB', lambda*' lesion', beta* ' lesion')) +
  # scale_fill_manual(values=modelPal, name = 'Model', labels = expression('GP-UCB', lambda*' lesion', beta* ' lesion')) +
  # facet_wrap(~group, nrow = 1)+
  # ggtitle('Model fits') +
  # theme_classic() +
  # theme(strip.background=element_blank(),
  #       legend.position = 'none', legend.justification = c(1,0), axis.title.x=element_blank())

```





## Analysis of parameter estimates



```{r}
df_gpucb_params <- modelFits %>% filter(kernel=='GP' & acq == 'UCB') %>% 
  pivot_longer(c('lambda', 'beta', 'tau'), names_to = 'param', values_to = 'estimate') %>% 
  mutate(param = factor(param, levels = c('lambda', 'beta', 'tau'))) #%>% 
  # mutate(group = case_match(group,
  #                           "PPD-" ~ "PD-",
  #                           "PPD+" ~ "PD+",
  #                           "PNP" ~ "PNP",
  #                           .default = NA)) %>% 
  # mutate(group = factor(group, levels = c("PNP", "PD+", "PD-")))  

ggboxplot(df_gpucb_params, 
          x = "group", 
          y = "estimate",
          color = "group", palette =groupcolors, fill = "group", alpha = 0.2,
          add = "jitter", jitter.size = 0.5, shape = "group", title = "GP-UCB parameter estimates") +
  facet_wrap(~param, nrow = 1) +
  scale_y_log10(breaks = c(0.01, 0.1, 1, 10, 100), labels = c("0.01", "0.1", "1", "10", "100")) +
  ylab("Estimate") +
  xlab("") +
  stat_compare_means(comparisons = list( c("PNP", "PD+"), c("PD+", "PD-"), c("PNP", "PD-")  ), 
                     paired = F, 
                     method = "t.test", 
                     # label = "p.format",
                     aes(label = paste0("p = ", after_stat(p.format)))
  ) +
  stat_summary(fun = mean, geom="point", shape = 23, fill = "white", size=2) +
  theme_classic() +
  theme(strip.background = element_blank(),  
        strip.text = element_text(color = "black", size=12),
        legend.position = "none"
  )

ggsave("plots/GP-UCB_params.png", width = 9, height = 5)
```

The increased exploration bonus $\beta$ aligns with findings from a restless bandit paradigm, where L-Dopa reduced the amount of directed exploration in healthy volunteers, while the level of undirected exploration was unaffected (@Chakroun2020restless_ldopa).

# Session Information

<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapseOne">

Session Information

</button>

:::: {#collapseOne .accordion-collapse .collapse}
<div>

```{r}
sessionInfo()
```

</div>
::::