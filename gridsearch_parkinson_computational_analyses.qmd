---
title: " Exploration and Exploitation in Parkinson’s Disease: Computational Analyses"
author: 
  - name: Björn Meder
    affiliation: Health and Medical University, Potsdam, Germany
  - name: Martha Sterf
    affiliation: Medical School Berlin, Berlin, Germany
  - name: Charley M. Wu
    affiliation: University of Tübingen, Tübingen, Germany
  - name: Matthias Guggenmos
    affiliation: Health and Medical University, Potsdam, Germany
date: "`r format(Sys.time(), '%d %B, %Y')`"
format:
  html:
    toc: true
    theme: zephyr
    code-fold: true
    toc-location: left-body
    classoption: fleqn
    lightbox: true
    number-sections: true
    number-figures: true
    self-contained: true
    grid:
      sidebar-width: 300px
      body-width: 1000px
      margin-width: 200px
      gutter-width: 1.5rem
  pdf:
    toc: true
    number-sections: true
    number-figures: true
  docx:
    toc: true
    number-sections: true
    number-figures: true
editor: 
  default: source
editor_options: 
  chunk_output_type: console
bibliography: gridsearch_parkinson.bib
csl: https://www.zotero.org/styles/apa
cite-method: citeproc
---


```{r, results = "hide", message=FALSE}
# Housekeeping: Load packages and helper functions
# Housekeeping
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(fig.align='center')

options(knitr.kable.NA = '')

packages <- c('gridExtra', 'BayesFactor', 'tidyverse', "RColorBrewer", "lme4", "sjPlot", "lsr", "brms", "kableExtra", "afex", "emmeans", "viridis", "ggpubr", "hms", "scales", "cowplot", "waffle", "ggthemes", "parameters")
lapply(packages, require, character.only = TRUE)

set.seed(0815)

# file with various statistical functions, among other things it provides tests for Bayes Factors (BFs)
source('statisticalTests.R')

# Wrapper for brm models such that it saves the full model the first time it is run, otherwise it loads it from disk
run_model <- function(expr, modelName, path='brm', reuse = TRUE) {
  path <- paste0(path,'/', modelName, ".brm")
  if (reuse) {
    fit <- suppressWarnings(try(readRDS(path), silent = TRUE))
  }
  if (is(fit, "try-error")) {
    fit <- eval(expr)
    saveRDS(fit, file = path)
  }
  fit
}


# Setting some plotting params
w_box          <- 0.2      # width of boxplot, also used for jittering points and lines    
line_jitter    <- w_box / 2
xAnnotate      <- -0.3

# jitter params
jit_height  <- 0.01
jit_width   <- 0.05
jit_alpha   <- 0.6

# colors for age groups
groupcolors <- c("#1b9e77", "#d95f02", "#7570b3")

```

```{r}
# read data
dat_gridsearch       <- read_delim("data/data_gridsearch_parkinson.csv", 
                        delim = ",",
                        col_types = cols(
                          #id = readr::col_factor(),
                          group = readr::col_factor(),
                          gender = readr::col_factor(),
                          z = col_double(),        
                          zscaled = col_double(),
                          hoehn_yahr = col_double()
                        ))

########################################################
# get subject data
########################################################
dat_sample <- read_delim("data/data_gridsearch_subjects.csv", escape_double = FALSE, trim_ws = TRUE, show_col_types = FALSE) %>% 
  mutate(gender = as.factor(gender),
         group  = factor(group, levels = c("PNP", "PD+", "PD-"))) %>% 
  mutate(last_ldopa = if_else(group != "PNP", as_hms(last_ldopa), as_hms(NA)),
         next_ldopa = if_else(group != "PNP", as_hms(next_ldopa), as_hms(NA)),
         time_exp = if_else(group != "PNP", as_hms(time_exp), as_hms(NA))) %>% 
  mutate(time_since_ldopa = as.numeric(time_exp - last_ldopa, unit = "mins"))

# combine behavioral and subject data
dat <- dat_sample %>% 
  left_join(dat_gridsearch, by = "id") %>% 
  arrange(group)

# length(unique(dat$id))
# clean up
dat <- dat %>%
  #select(-condition, -comments) %>% 
  # mutate(group = case_match(group,
  #                           "PPD-" ~ "PD-",
  #                           "PPD+" ~ "PD+",
  #                           "PNP" ~ "PNP",
  #                           .default = NA)) %>% 
  mutate(group = factor(group, levels = c("PNP", "PD+", "PD-")))  %>% 
  mutate(type_choice = factor(type_choice, levels = c("Repeat", "Near", "Far")))  %>% 
  mutate(gender = recode(gender, "w" = "f")) %>% 
  # rename(MMSE = `mini_mental`) %>% 
  mutate(last_ldopa = if_else(group != "PNP", as_hms(last_ldopa), as_hms(NA)),
         next_ldopa = if_else(group != "PNP", as_hms(next_ldopa), as_hms(NA)),
         time_exp = if_else(group != "PNP", as_hms(time_exp), as_hms(NA))) %>% 
  mutate(time_since_ldopa = as.numeric(time_exp - last_ldopa, unit = "mins"))

# get subject information
df_sample <- dat %>% 
  select(id, age, gender,group,BDI,MMSE,hoehn_yahr,last_ldopa,next_ldopa,time_exp,time_since_ldopa) %>% 
  group_by(id) %>%
  slice_head(n = 1) %>% 
  arrange(group)

# head(dat) %>%
#   kable("html", caption = "Behavioral data.") %>%
#   kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F) %>% 
#   scroll_box(width = "100%", height = "300px")

```

# Computational Analyses

Complementing the behavioral analyses, we study exploration and exploitation in PD through the lens of a computational model, the Gaussian Process Upper Confidence Bound (GP-UCB) model. This model integrates similarity-based generalization with two distinct exploration mechanisms: _directed exploration_, which seeks to reduce uncertainty about rewards, and _random exploration_, which adds stochastic noise to the search process without being directed towards a particular goal [@Wu_2018grid; @Wu_et_al-generalization2025]. In previous research using the same paradigm, this model has provided the best account of human behavior and enabled the decomposition of exploration into distinct mechanisms
[@Wu_2018grid; @Schulz:2019kwg; @Wu:2020neurogrid; @Meder2021_ExplorationChildren; @giron2023developmental].


## Gaussian Process Upper Confidence Bound (GP-UCB) Model

The GP-UCB model comprises three components:

1. a _learning model_, which uses Bayesian inference to generate predictions about the rewards associated with each option (tile),
2. a _sampling strategy_, which uses reward expectations and associated uncertainty to evaluate how promising each option is, and
3. a _choice rule_, which converts options' values into choice probabilities.

::: callout-note
Add details
:::
### Learning Model
### Sampling Strategy
### Choice rule

### Model parameters
Associated with each model component is a free parameter that we estimate through out-of-sample cross validation. These parameters provide a window into distinct aspects of learning and exploration: 

1. The length-scale parameter $\lambda$ of the RBF kernel captures how strongly a participant generalizes based on the observed evidence, i.e., the rewards obtained from previous choices.
2. The uncertainty bonus $\beta$ represents to the level of directed exploration, i.e., how much expected rewards are inflated through an "uncertainty bonus".
3. The temperature parameter $\tau$ corresponds to the amount of sampling noise, i.e., extent of random exploration. 

## Model comparison

We tested the GP-UCB model in its ability to model learning and predicting each participants' search and decision-making behavior. To assess the contribution of each component of the model (generalization, uncertainty-directed exploration, and random exploration) we compare the predictive accuracy of the GP-UCB model to model variants where we lesion away each component.

$\lambda$ lesion model

$\beta$ lesion model

$\tau$ lesion model


All models were fitted using leave-one-round-out cross-validation based on maximum likelihood estimation. Model fits are evaluated using the sum of negative log-likelihoods across all out-of-sample predictions.

Models' predictive accuracy was assessed using a pseudo-$R^2$ measure, based on the sum of negative log-likelihoods across all out-of-sample predictions. The summed log loss is compared to a random model, such that $R^2=0$ corresponds to chance performance and $R^2=1$ corresponds to theoretically perfect predictions. 

$$
R^2 = 1 - \frac{\log \mathcal{L}(M_k)}{\log\mathcal{L}(M_{rand})},
$$



```{r}
#| fig-cap: "Predictive accuracy of GP-UCB model and lesioned variants."
#| label: fig-model_comparison

modelFits <- read.csv('modelResults/modelFit.csv') # generated by dataProcessing_gridSearchParkinson.R
# length(unique(modelFits$id))

groupDF <- dat %>% 
  group_by(id) %>%
  slice(1) %>%
  ungroup()

# length(unique(dat$id))
# length(unique(groupDF$id))

modelFits <- merge(modelFits, groupDF[,c('id', 'group')], by = "id") # merge to add group 

# kernels <- c("RBF", "BMT") # RBF = Radial Basis Function kernel, BMT= Bayesian Mean Tracker
# acqFuncs <- c("GM", "UCB", "EG") # UCB = Upper Confidence Bound, GM=greedyMean, EG = epsilonGreedy
modelFits <-  modelFits %>%
  mutate(kernel=factor(kernel, levels=c('RBF', 'BMT'), labels=c('GP', 'BMT'))) %>%
  mutate(acq=factor(acq, levels=c('UCB', 'GM','epsilonGreedy'), labels=c('UCB', 'meanGreedy', 'epsilonGreedy')))

modelFits$ModelName = paste(modelFits$kernel, modelFits$acq, sep="-")

# Only include key comparisons
modelFits <- subset(modelFits, ModelName %in% c("GP-UCB", "BMT-UCB", "GP-meanGreedy", "GP-epsilonGreedy" ))
modelFits$ModelName = factor(modelFits$ModelName, levels = c('GP-UCB', 'BMT-UCB', 'GP-meanGreedy', 'GP-epsilonGreedy'))

#Two line name for models
modelFits$shortname <- factor(modelFits$ModelName, labels = c('GP\nUCB', 'lambda\nlesion', 'beta\nlesion', 'tau\nlesion'))
levels(modelFits$shortname) <- c('GP\nUCB', 'lambda\nlesion', 'beta\nlesion', 'tau\nlesion')

ggboxplot(modelFits, 
          x = "shortname", 
          y = "R2",
          color = "group", palette =groupcolors, fill = "group", alpha = 0.2,
          add = "jitter", jitter.size = 1, shape = "group", title = "Model comparison") +
  facet_wrap(~group, nrow = 1) +
  ylab(bquote(R^2)) +
  xlab("") +
  stat_compare_means(
    comparisons = list( 
      c("GP\nUCB", "lambda\nlesion"), 
      c("GP\nUCB", "beta\nlesion"), 
      c("GP\nUCB", "tau\nlesion")  
    ), 
    paired = TRUE, 
    method = "t.test", 
    aes(label = paste0("p = ", after_stat(p.format)))
    
  ) +
  stat_summary(fun = mean, geom="point", shape = 23, fill = "white", size=2) +
  theme_classic() +
  theme(strip.background = element_blank(),  
        strip.text = element_text(color = "black", size=12),
        legend.position = "none"
  )

ggsave("plots/model_comparison.png", width = 9, height = 5)

```


### Classification of participants according to model accuracy

```{r}
# classify participants according to model R^2
df_participant_classification <- modelFits %>%
  group_by(id) %>%
  slice_max(order_by = R2, n = 1) %>%
  select(id, group, ModelName, shortname, R2) %>% 
  ungroup() %>% 
  rename(best_ModelName = ModelName,
         best_shortname = shortname,
         best_R2 = R2)

df_counts <- df_participant_classification %>%
  count(group, best_shortname)

df_percent <- df_counts %>%
  group_by(group) %>%
  mutate(
    total_in_group = sum(n),
    percent = round((n / total_in_group) * 100, 1)
  ) %>%
  ungroup()

# add most predictive model for each subject to df modelFits
modelFits <- modelFits %>% 
  left_join(df_participant_classification, by = c("id", "group"))


```

We classified participants based on which model achieved the highest cross-validated predictive accuracy (highest $R^2$; @fig-participant_classification). In each patient group, the GP-UCB model was the most rpedictive model for the majority of participants (PNP: `r df_percent %>% filter(group == "PNP", best_shortname == "GP\nUCB") %>% pull(percent)`%, PD+: `r df_percent %>% filter(group == "PD+", best_shortname == "GP\nUCB") %>% pull(percent)`%, PD-: `r df_percent %>% filter(group == "PD-", best_shortname == "GP\nUCB") %>% pull(percent)`%).

In total, out of `r sum(df_counts$n)` participants, `r sum(df_counts$n[df_counts$best_shortname == "GP\nUCB"])` (`r round(sum(df_counts$n[df_counts$best_shortname == "GP\nUCB"]) / sum(df_counts$n),3)*100`%) were best described by the GP-UCB model, `r sum(df_counts$n[df_counts$best_shortname == "lambda\nlesion"])` (`r round(sum(df_counts$n[df_counts$best_shortname == "lambda\nlesion"]) / sum(df_counts$n),3)*100`%) by the lambda lesion model, `r sum(df_counts$n[df_counts$best_shortname == "beta\nlesion"])`  (`r round(sum(df_counts$n[df_counts$best_shortname == "beta\nlesion"]) / sum(df_counts$n),3)*100`%) by the beta lesion model, and `r sum(df_counts$n[df_counts$best_shortname == "tau\nlesion"])` (`r round(sum(df_counts$n[df_counts$best_shortname == "tau\nlesion"]) / sum(df_counts$n),3)*100`%) by the tau lesion model. The results suggest that all three components of the GP-UCB model are relevant for predicting participants' behavior.

```{r}
#| fig-cap: "Classification of participants by models' cross-validated predictive accuracy. Each square is one participant, coloured according to the model that best predicted their perfomance (=highest R2)."
#| label: fig-participant_classification
#| fig-width: 12


# waffle plot
ggplot(
  data = df_counts, 
  aes(fill=best_shortname, values=n)
) +
  geom_waffle(
    color = "white", 
    size = 1, 
    n_rows = 5
  ) +
  facet_wrap(~group, nrow=1) +
  scale_x_discrete(
    expand = c(0,0,0,0)
  ) +
  scale_y_discrete(
    expand = c(0,0,0,0)
  ) +
  ggthemes::scale_fill_tableau(name=NULL) +
  coord_equal() +
  labs(
    title = "Model-Based Participant Classification"
  ) +
theme_classic() +
  theme(
    legend.title = element_blank(),
    plot.title = element_text(size = 18),
    legend.position = 'bottom',
    strip.text = element_text(size=14),
    legend.text =  element_text(colour="black", size=14),
    text = element_text(colour = "black"),
    strip.background =element_blank(),
    axis.text.x = element_text(colour="black", size = 14),
    axis.text.y = element_text(colour="black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.spacing = unit(3, "lines"))

ggsave("plots/participant_classification.png", width = 8, height = 4, dpi=300)

```


## Analysis of parameter estimates

```{r}
#| fig-cap: "Parameter estimates of GP-UCB model, estimated through leave-one-round-out cross validation. Each dot is one participant."
#| label: fig-GP-CUB_params
#| fig-width: 12


df_gpucb_params <- modelFits %>% filter(kernel=='GP' & acq == 'UCB') %>% 
  pivot_longer(c('lambda', 'beta', 'tau'), names_to = 'param', values_to = 'estimate') %>% 
  mutate(param = factor(param, levels = c('lambda', 'beta', 'tau'))) %>% 
  mutate(estimate_log10 = estimate)

# make boxplot
ggboxplot(df_gpucb_params, 
          x = "group", 
          y = "estimate",
          color = "group", palette =groupcolors, fill = "group", alpha = 0.2,
          add = "jitter", jitter.size = 0.5, shape = "group", title = "GP-UCB parameter estimates") +
  facet_wrap(~param, nrow = 1) +
  scale_y_log10(breaks = c(0.01, 0.1, 1, 10, 100), labels = c("0.01", "0.1", "1", "10", "100")) +
  ylab("Estimate (log scale") +
  xlab("") +
  # not correct because runs on log-transformed values
  # stat_compare_means(comparisons = list( c("PNP", "PD+"), c("PD+", "PD-"), c("PNP", "PD-")  ), 
  #                    paired = F, 
  #                    method = "t.test", 
  #                    # label = "p.format",
  #                    aes(label = paste0("p = ", after_stat(p.format)))
  # ) +
  stat_summary(fun = mean, geom="point", shape = 23, fill = "white", size=2) +
  theme_classic() +
  theme(strip.background = element_blank(),  
        strip.text = element_text(color = "black", size=12),
        legend.position = "none",
        plot.title = element_text(size = 18)
  )
  
  
ggsave("plots/GP-UCB_params.png", width = 9, height = 5)

```


To better understand the mechanisms underlying the observed behavioral differences, we analyzed the parameters of the Gaussian Process Upper Confidence Bound (GP-UCB) model (@fig-GP-CUB_params). 

### Lambda $\lambda$
The parameter $\lambda$ represents the length-scale in the RBF kernel, which governs the amount of generalization, i.e., to what extent participants assume a spatial correlation between options (higher $\lambda$ = stronger generalization). Overall, the amount of generalization was very similar between groups. 

- PNP vs. PD+: `r ttestPretty(subset(df_gpucb_params, group == 'PNP' & param=="lambda")$estimate, subset(df_gpucb_params, group == 'PD+' & param=="lambda")$estimate,var.equal = TRUE)`
- PNP vs. PD-: `r ttestPretty(subset(df_gpucb_params, group == 'PNP' & param=="lambda")$estimate, subset(df_gpucb_params, group == 'PD-' & param=="lambda")$estimate,var.equal = TRUE)`
- PD+ vs. PD-: `r ttestPretty(subset(df_gpucb_params, group == 'PD+' & param=="lambda")$estimate, subset(df_gpucb_params, group == 'PD-' & param=="lambda")$estimate,var.equal = TRUE)`

### Beta $\beta$
The parameter $\beta$ represents the uncertainty bonus, i.e. how much expected rewards are positively inflated by their uncertainty (higher $\beta$ = stronger generalization). 

- PNP vs. PD+: `r ttestPretty(subset(df_gpucb_params, group == 'PNP' & param=="beta")$estimate, subset(df_gpucb_params, group == 'PD+' & param=="beta")$estimate,var.equal = TRUE)`
- PNP vs. PD-: `r ttestPretty(subset(df_gpucb_params, group == 'PNP' & param=="beta")$estimate, subset(df_gpucb_params, group == 'PD-' & param=="beta")$estimate,var.equal = TRUE)`
- PD+ vs. PD-: `r ttestPretty(subset(df_gpucb_params, group == 'PD+' & param=="beta")$estimate, subset(df_gpucb_params, group == 'PD-' & param=="beta")$estimate,var.equal = TRUE)`


### tau $\beta$
The parameter $\tau$ represents the amount of decision noise, i.e. stochastic variability in the softmax decision rule (lower $\tau$ = more decision noisy, with \beta \rightarrow \infty \quad \Rightarrow \quad \text{argmax (greedy)}). 

- PNP vs. PD+: `r ttestPretty(subset(df_gpucb_params, group == 'PNP' & param=="tau")$estimate, subset(df_gpucb_params, group == 'PD+' & param=="tau")$estimate,var.equal = TRUE)`
- PNP vs. PD-: `r ttestPretty(subset(df_gpucb_params, group == 'PNP' & param=="tau")$estimate, subset(df_gpucb_params, group == 'PD-' & param=="tau")$estimate,var.equal = TRUE)`
- PD+ vs. PD-: `r ttestPretty(subset(df_gpucb_params, group == 'PD+' & param=="tau")$estimate, subset(df_gpucb_params, group == 'PD-' & param=="tau")$estimate,var.equal = TRUE)`


The increased exploration bonus $\beta$ aligns with findings from a restless bandit paradigm, where L-Dopa reduced the amount of directed exploration in healthy volunteers, while the level of undirected exploration was unaffected [@Chakroun2020restless_ldopa].



### Correlation of Model Parameters with Performance

The amount of generalization was positively related with obtained rewards, showing that participants who successfully learned about the spatially correlation of rewards were performing better.



```{r}
#| fig-cap: "Correlation of GP-UCB parameters with obtained mean reward across all trials and rounds. Each dot is one participant. The insets show the correlations for a restricted parameter range from 0 to 1."
#| label: fig-params_reward_cor
#| fig-width: 12
#| fig-height: 5

# mean reward per subject across all trials and rounds (practice and bonus round excluded)
df_mean_reward_subject <- dat %>% 
  filter(trial != 0 & round %in% 2:9) %>% # exclude first (randomly revealed) tile and practice round and bonus round
  group_by(id) %>% 
  summarise(group = first(group),
            sum_reward = sum(z),
            mean_reward = mean(z), 
            sd_reward = sd(z)) 

df_params_performance <- df_gpucb_params %>% 
  left_join(df_mean_reward_subject, by = c("id", "group"))

df_params_performance_wide <- df_gpucb_params %>% 
  pivot_wider(names_from = param, values_from = estimate ) %>% 
  left_join(df_mean_reward_subject, by = c("id", "group"))

# p_GP_UCB_params_cor_reward <-  ggscatter(df_params_performance, x = "estimate", y = "mean_reward",
#    add = "reg.line",  
#    add.params = list(color = "darkred", fill = "lightgray"), 
#    conf.int = TRUE 
#    ) +
#    facet_wrap(~param, scales = "free_x") +
#    #stat_cor(method = "kendall", label.x = c(0,3,3), label.y = 45) +
#    scale_x_log10(breaks = c(0.001, 0.01, 0.1, 1, 10, 100), labels = c("0.001", "0.01", "0.1", "1", "10", "100")) +
#    ggtitle("Correlation between GP-UCB parameters and reward") +
#   theme_classic() +
#   theme(strip.background = element_blank(),  
#         strip.text = element_text(color = "black", size=12),
#         legend.title = element_blank())
#  
#  ggsave("plots/GP-UCB_params_cor_reward.png", p_GP_UCB_params_cor_reward, width = 12, height= 4, dpi=300)


# plot correlation between parameter estimates and mean reward, with inset for smaller estimate range (ie. removal of outliers to test whether corrleation remains stable)
main_plot <- ggscatter(df_params_performance, x = "estimate", y = "mean_reward",
                       add = "reg.line",  
                       add.params = list(color = "darkred", fill = "lightgray"), 
                       conf.int = TRUE 
) +
  facet_wrap(~param, scales = "free_x") +
  stat_cor(method = "pearson", label.x = c(0,3,3), label.y = 45) +
  ggtitle("Correlation between GP-UCB parameters and reward") +
  scale_y_continuous("Mean reward", breaks = seq(0,45,10)) +
  xlab("Estimate") +
  theme_classic() +
  theme(strip.background = element_blank(),  
        strip.text = element_text(color = "black", size=12),
        legend.title = element_blank())

# Inset-Plot für beta (nur Werte 0-1)
inset_beta <- 
  ggscatter(df_params_performance %>% filter(param == "beta" & estimate > 0 & estimate <= 1), 
            x = "estimate", y = "mean_reward",
            add = "reg.line",  
            add.params = list(color = "darkred", fill = "lightgray"), 
            conf.int = TRUE 
  ) +
  stat_cor(method = "pearson", label.x = 0.1, label.y = 42, size = 3) +
  scale_x_continuous(breaks = seq(0,1,0.1)) +
  theme_classic() +
  theme(axis.title = element_blank(),strip.background = element_blank(), strip.text = element_blank(), legend.position = "none")

# Inset-Plot für tau (nur Werte 0-1)
inset_tau <- 
  ggscatter(df_params_performance %>% filter(param == "tau" & estimate > 0 & estimate <= 1), 
            x = "estimate", y = "mean_reward",
            add = "reg.line",  
            add.params = list(color = "darkred", fill = "lightgray"), 
            conf.int = TRUE 
  ) +
  stat_cor(method = "pearson", label.x = 0.1, label.y = 42, size = 3) +
  scale_x_continuous(breaks = seq(0,1,0.1)) +
  theme_classic() +
  theme(axis.title = element_blank(),strip.background = element_blank(), strip.text = element_blank(), legend.position = "none")


# Hauptplot mit Insets für beta und tau
p_GP_UCB_params_cor_reward_inset <- 
  ggdraw(main_plot) +
  draw_plot(inset_beta, x = 0.5, y = 0.5, width = 0.15, height = 0.3) +
  draw_plot(inset_tau, x = 0.8, y = 0.5, width = 0.15, height = 0.3)

p_GP_UCB_params_cor_reward_inset

ggsave("plots/GP-UCB_params_cor_reward.png", p_GP_UCB_params_cor_reward_inset, width = 12, height= 4, dpi=300)


# wilcox.test(df_params_performance_wide$mean_reward, df_params_performance_wide$lambda, paired = T)
# cor(df_params_performance_wide$lambda,df_params_performance_wide$mean_reward, method = "kendall", paired=T)
# ranktestPretty(df_params_performance_wide$mean_reward, df_params_performance_wide$lambda, paired=T)

# plot with individual lines for each group (from Meder et al., 2021)
# p_lambda_vs_reward <- 
  # 
  # ggplot(df_params_performance_wide, aes(x = lambda, y=mean_reward, group = group, fill = group, color = group)) +
  # geom_smooth(linetype = "dashed", size = 1, method="lm", se=F, alpha = 0.2) +
  # geom_point(shape = 21, alpha = 0.8, colour = "black") +
  # scale_fill_manual(values = groupcolors) +
  # scale_color_manual(values = groupcolors) + 
  # scale_y_continuous("Mean reward")+  
  # scale_x_continuous(expression(paste("Generalization ", lambda)), trans="log10", breaks = c(.01, .1, 1, 10, 100), labels = c(.01, .1, 1, 10, 100)) +
  # ggtitle(expression(paste("Generalization ", lambda, " and performance"))) +
  # theme_classic() +
  # theme(aspect.ratio = 1,
  #       plot.title = element_text(hjust = 0.5, size = 12),
  #       legend.title = element_blank(),
  #       legend.position = c(.8,.1),
  #       legend.spacing.x = unit(0.01, 'cm'),
  #       legend.key.size = unit(0.5, "cm"),
  #       legend.background = element_blank(),
  #       legend.text =  element_text(colour="black", size = 10),
  #       strip.background = element_blank(),
  #       text = element_text(colour = "black"),
  #       axis.text =  element_text(colour = "black"),
  #       panel.grid.major = element_blank(),
  #       panel.grid.minor = element_blank())

```


# Appendix
```{r}
#| fig-cap: "Parameter estimates of GP-UCB model, estimated through leave-one-round-out cross validation. Each dot is one participant.Only participants are included who were best described by the GP-UCB model."
#| label: fig-GP-CUB_params_subset
#| fig-width: 12


df_gpucb_params_subset <- modelFits %>% 
  filter(best_ModelName == "GP-UCB") %>% 
  filter(kernel=='GP' & acq == 'UCB') %>% 
  pivot_longer(c('lambda', 'beta', 'tau'), names_to = 'param', values_to = 'estimate') %>% 
  mutate(param = factor(param, levels = c('lambda', 'beta', 'tau'))) 


ggboxplot(df_gpucb_params_subset, 
          x = "group", 
          y = "estimate",
          color = "group", palette =groupcolors, fill = "group", alpha = 0.2,
          add = "jitter", jitter.size = 0.5, shape = "group", title = "GP-UCB parameter estimates") +
  facet_wrap(~param, nrow = 1) +
  scale_y_log10(breaks = c(0.01, 0.1, 1, 10, 100), labels = c("0.01", "0.1", "1", "10", "100")) +
  ylab("Estimate (log scale") +
  xlab("") +
  stat_summary(fun = mean, geom="point", shape = 23, fill = "white", size=2) +
  theme_classic() +
  theme(strip.background = element_blank(),  
        strip.text = element_text(color = "black", size=12),
        legend.position = "none",
        plot.title = element_text(size = 18)
  )
  
  
ggsave("plots/GP-UCB_params_subset.png", width = 9, height = 5)

```


# Session Information

<button class="accordion-button" type="button" data-bs-toggle="collapse" data-bs-target="#collapseOne">

Session Information

</button>

:::: {#collapseOne .accordion-collapse .collapse}
<div>

```{r}
sessionInfo()
```

</div>
::::